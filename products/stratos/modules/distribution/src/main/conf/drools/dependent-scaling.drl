/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *  http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */

package org.apache.stratos.autoscaler.rule;

import org.apache.stratos.autoscaler.context.cluster.ClusterInstanceContext;
import org.apache.stratos.autoscaler.algorithm.AutoscaleAlgorithm;
import org.apache.stratos.autoscaler.context.partition.ClusterLevelPartitionContext;
import org.apache.stratos.autoscaler.context.member.MemberStatsContext;
import org.apache.stratos.autoscaler.pojo.policy.autoscale.RequestsInFlight;
import org.apache.stratos.autoscaler.pojo.policy.autoscale.LoadThresholds;
import org.apache.stratos.autoscaler.pojo.policy.autoscale.MemoryConsumption;
import org.apache.stratos.autoscaler.pojo.policy.autoscale.LoadAverage;

global org.apache.stratos.autoscaler.rule.RuleLog log;
global java.lang.String clusterId;
global Integer roundedRequiredInstanceCount;
global org.apache.stratos.autoscaler.rule.RuleTasksDelegator delegator;
global java.lang.String algorithmName;
global java.lang.Boolean isPrimary;
global java.util.List primaryMembers;

rule "Dependent Scaling Rule"
dialect "mvel"
	when

        clusterInstanceContext : ClusterInstanceContext ()
        autoscaleAlgorithm : AutoscaleAlgorithm() from  delegator.getAutoscaleAlgorithm(algorithmName)

        eval(log.debug("Running dependent scaling rule: [network-partition] " + clusterInstanceContext.getNetworkPartitionId() + " [cluster-instance] " + clusterInstanceContext.getId()))
        scaleUp : Boolean() from (clusterInstanceContext.getNonTerminatedMemberCount() < roundedRequiredInstanceCount )
        scaleDown : Boolean() from (clusterInstanceContext.getNonTerminatedMemberCount() > roundedRequiredInstanceCount )

	then

        if(scaleUp) {

            int additionalInstances = roundedRequiredInstanceCount - clusterInstanceContext.getNonTerminatedMemberCount();
            int count = 0;

            while(count != additionalInstances){
            ClusterLevelPartitionContext partitionContext =  (ClusterLevelPartitionContext)autoscaleAlgorithm.getNextScaleUpPartitionContext(clusterInstanceContext.getPartitionCtxtsAsAnArray());
                if(partitionContext != null){
                    log.info("[scale-up] Partition available, hence trying to spawn an instance to scale up!" );
                    log.debug("[scale-up] " + " [partition] " + partitionContext.getPartitionId() + " [cluster] " + clusterId );
                    delegator.delegateSpawn(partitionContext, clusterId, clusterInstanceContext.getId(), isPrimary);
                    count++;
                }
            }
        } else if (scaleDown) {

            int redundantInstances = clusterInstanceContext.getNonTerminatedMemberCount() - roundedRequiredInstanceCount;

            int count = 0;

            while(count != redundantInstances){
                MemberStatsContext selectedMemberStatsContext = null;
                double lowestOverallLoad = 0.0;
                boolean foundAValue = false;
                ClusterLevelPartitionContext partitionContext =  (ClusterLevelPartitionContext)autoscaleAlgorithm.getNextScaleDownPartitionContext(clusterInstanceContext.getPartitionCtxtsAsAnArray());
                if(partitionContext != null){
                    log.info("[scale-down] Partition available to scale down, hence trying to terminate an instance to scale down!" );
                    log.debug("[scale-down] " + " [partition] " + partitionContext.getPartitionId() + " [cluster] " + clusterId );

                    for(MemberStatsContext memberStatsContext: partitionContext.getMemberStatsContexts().values()){

						if( !primaryMembers.contains(memberStatsContext.getMemberId()) ) {

                            LoadAverage loadAverage = memberStatsContext.getLoadAverage();
                            log.debug("[scale-down] " + " [cluster] "
                                + clusterId + " [member] " + memberStatsContext.getMemberId() + " Load average: " + loadAverage);

                            MemoryConsumption memoryConsumption = memberStatsContext.getMemoryConsumption();
                            log.debug("[scale-down] " + " [partition] " + partitionContext.getPartitionId() + " [cluster] "
                                + clusterId + " [member] " + memberStatsContext.getMemberId() + " Memory consumption: " + memoryConsumption);

                            double predictedCpu = delegator.getPredictedValueForNextMinute(loadAverage.getAverage(),loadAverage.getGradient(),loadAverage.getSecondDerivative(), 1);
                            log.debug("[scale-down] " + " [partition] " + partitionContext.getPartitionId() + " [cluster] "
                                + clusterId + " [member] " + memberStatsContext.getMemberId() + " Predicted CPU: " + predictedCpu);

                            double predictedMemoryConsumption = delegator.getPredictedValueForNextMinute(memoryConsumption.getAverage(),memoryConsumption.getGradient(),memoryConsumption.getSecondDerivative(), 1);
                            log.debug("[scale-down] " + " [partition] " + partitionContext.getPartitionId() + " [cluster] "
                                + clusterId + " [member] " + memberStatsContext.getMemberId() + " Predicted memory consumption: " + predictedMemoryConsumption);

                            double overallLoad = (predictedCpu + predictedMemoryConsumption) / 2;
                            log.debug("[scale-down] " + " [partition] " + partitionContext.getPartitionId() + " [cluster] "
                                + clusterId + " [member] " + memberStatsContext.getMemberId() + " Overall load: " + overallLoad);

                            if(!foundAValue){
                                foundAValue = true;
                                selectedMemberStatsContext = memberStatsContext;
                                lowestOverallLoad = overallLoad;
                            } else if(overallLoad < lowestOverallLoad){
                                selectedMemberStatsContext = memberStatsContext;
                                lowestOverallLoad = overallLoad;
                            }


					    }

                    }
                    if(selectedMemberStatsContext != null) {
                        log.info("[scale-down] Trying to terminating an instace to scale down!" );
                        log.debug("[scale-down] " + " [partition] " + partitionContext.getPartitionId() + " [cluster] "
                            + clusterId + " Member with lowest overall load: " + selectedMemberStatsContext.getMemberId());

                        delegator.delegateTerminate(partitionContext, selectedMemberStatsContext.getMemberId());
                    }

                    count++;
                }
            }
        }

end




